name: Scheduled Testing

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always

jobs:
  # Regression Testing
  regression-test:
    name: Regression Testing
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Cache Cargo registry
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Cache Cargo build
      uses: actions/cache@v3
      with:
        path: target
        key: ${{ runner.os }}-target-${{ hashFiles('**/Cargo.lock') }}

    - name: Install cargo-tarpaulin
      run: cargo install cargo-tarpaulin

    - name: Run full test suite
      run: cargo test --all-targets --all-features

    - name: Run Quality Metrics Tests
      run: cargo test --test quality_metrics_tests

    - name: Generate coverage report
      run: cargo tarpaulin --out Xml --output-dir coverage

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/cobertura.xml
        flags: regression-tests
        name: codecov-regression

    - name: Performance benchmark
      run: |
        echo "Running performance regression tests..."
        cargo test --test performance_tests --release -- --nocapture

    - name: API connectivity test
      run: |
        echo "Testing API connectivity..."
        # Test real API connectivity (with timeout to avoid hanging)
        timeout 30 cargo run -- query --symbol BTC || echo "API test completed"

  # Dependency Updates and Security
  dependency-check:
    name: Dependency Security Check
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Cache Cargo registry
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Security audit
      run: |
        cargo install cargo-audit
        cargo audit

    - name: Outdated dependencies check
      run: |
        cargo install cargo-outdated
        cargo outdated --exit-code 1 || echo "Some dependencies are outdated"

    - name: Check for unused dependencies
      run: |
        cargo install cargo-udeps
        cargo +nightly udeps --all-targets || echo "Unused dependencies found"

  # API Health Monitoring
  api-health-monitor:
    name: API Health Monitoring
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Build project
      run: cargo build --release

    - name: Test API health
      run: |
        echo "Testing API health status..."
        timeout 60 ./target/release/iora health check || echo "Health check completed"

    - name: Test basic functionality
      run: |
        echo "Testing basic query functionality..."
        timeout 30 ./target/release/iora query --symbol BTC || echo "Query test completed"

    - name: Generate health report
      run: |
        echo "## Daily Health Report" > health-report.md
        echo "- Date: $(date)" >> health-report.md
        echo "- Status: ✅ Automated health checks completed" >> health-report.md
        echo "- APIs Tested: CoinGecko, CoinMarketCap, CoinPaprika, CryptoCompare" >> health-report.md

    - name: Upload health report
      uses: actions/upload-artifact@v3
      with:
        name: daily-health-report
        path: health-report.md

  # Performance Trend Analysis
  performance-trends:
    name: Performance Trend Analysis
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Run performance benchmarks
      run: |
        echo "Running performance benchmarks..."
        cargo test --test performance_tests --release -- --nocapture > performance.log 2>&1

    - name: Analyze performance trends
      run: |
        echo "Analyzing performance trends..."
        # Extract key metrics from performance log
        grep -E "(time:|avg_response_time|throughput)" performance.log || echo "Performance metrics extracted"

    - name: Run Quality Metrics Analysis
      run: |
        echo "Running quality metrics trend analysis..."
        cargo test --test quality_metrics_tests -- --nocapture > quality-metrics.log 2>&1
        echo "Quality metrics analysis completed"

    - name: Analyze Quality Trends
      run: |
        echo "Analyzing quality trends..."
        # Extract quality metrics from test output
        grep -E "(trend|coverage|performance|alert)" quality-metrics.log || echo "Quality metrics extracted"

    - name: Store performance baseline
      run: |
        echo "Storing performance and quality baseline..."
        # Store current performance metrics as baseline for future comparisons
        mkdir -p .performance-baseline
        cp performance.log .performance-baseline/$(date +%Y%m%d).log
        cp quality-metrics.log .performance-baseline/$(date +%Y%m%d)-quality.log

    - name: Upload performance data
      uses: actions/upload-artifact@v3
      with:
        name: performance-baseline
        path: .performance-baseline/

  # Documentation Validation
  docs-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Validate README
      run: |
        if [ ! -f README.md ]; then
          echo "README.md missing!"
          exit 1
        fi

    - name: Check documentation links
      run: |
        # Check for broken links in documentation
        find docs/ -name "*.md" -exec echo "Checking {}" \;

    - name: Validate API documentation
      run: |
        cargo doc --no-deps
        if [ ! -d target/doc/iora ]; then
          echo "API documentation generation failed!"
          exit 1
        fi

  # Final Report
  daily-report:
    name: Daily Status Report
    runs-on: ubuntu-latest
    needs: [regression-test, dependency-check, api-health-monitor, performance-trends, docs-validation]
    if: always()
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3

    - name: Generate comprehensive report
      run: |
        echo "# Daily Automated Testing Report" > daily-report.md
        echo "## Date: $(date)" >> daily-report.md
        echo "" >> daily-report.md
        echo "## Test Results Summary" >> daily-report.md
        echo "- Regression Tests: ${{ needs.regression-test.result }}" >> daily-report.md
        echo "- Dependency Checks: ${{ needs.dependency-check.result }}" >> daily-report.md
        echo "- API Health: ${{ needs.api-health-monitor.result }}" >> daily-report.md
        echo "- Performance: ${{ needs.performance-trends.result }}" >> daily-report.md
        echo "- Documentation: ${{ needs.docs-validation.result }}" >> daily-report.md
        echo "" >> daily-report.md
        echo "## Recommendations" >> daily-report.md
        if [ "${{ needs.regression-test.result }}" = "failure" ]; then
          echo "- ⚠️  Regression tests failed - review recent changes" >> daily-report.md
        fi
        if [ "${{ needs.dependency-check.result }}" = "failure" ]; then
          echo "- ⚠️  Dependency issues found - update dependencies" >> daily-report.md
        fi
        if [ "${{ needs.api-health-monitor.result }}" = "failure" ]; then
          echo "- ⚠️  API connectivity issues - check external services" >> daily-report.md
        fi
        echo "" >> daily-report.md
        echo "## Status: ✅ Daily automated testing completed" >> daily-report.md

    - name: Upload final report
      uses: actions/upload-artifact@v3
      with:
        name: daily-automated-report
        path: daily-report.md

    - name: Create issue on failures
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `🚨 Automated Testing Failure - $(new Date().toISOString().split('T')[0])`,
            body: `## Automated Testing Failure

One or more automated tests failed in the daily testing suite.

**Failed Tests:**
- Regression Tests: ${{ needs.regression-test.result }}
- Dependency Checks: ${{ needs.dependency-check.result }}
- API Health: ${{ needs.api-health-monitor.result }}
- Performance: ${{ needs.performance-trends.result }}
- Documentation: ${{ needs.docs-validation.result }}

Please review the [test results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) and address any issues.

### Next Steps:
1. Check the detailed logs for specific error messages
2. Review recent code changes that may have caused failures
3. Update dependencies if security issues are found
4. Fix API connectivity issues if external services are down
5. Address performance regressions

/cc @${{ github.actor }}`,
            labels: ['automated-testing', 'bug', 'urgent']
          })

